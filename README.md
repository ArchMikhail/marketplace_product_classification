# Задача по предсказанию категории товара (многоклассовая классификация)

## 1. EDA

[Датасет](https://drive.google.com/drive/folders/1a1OwG0gUEovQLiMSIfiSHA2g3DsZ62P0) представлен таблицей, содержащей описания товаров и их характеристики, а также изображениями товаров. Анализ датасета показал, что исходные данные строго структурированы и не содержат пропусков и дублей. Однако в представлении самих данных наблюдаются серьезные различия. Например, в одном случае описание товара может быть крайне [лаконичным](https://kazanexpress.ru/product/Futbolka-muzhskaya-1583656), в [другом](https://kazanexpress.ru/product/Chekhol-s-karmanom-1805576) наоборот, представлять собой сложную структуру с html тегами, дополнительными изображениями, видео и другой информацией, в том числе маркетинговой, не имеющей непосредственного отношения к содержимому этого раздела данных о товаре.

#### Структура данных

**product_id** - идентификатор товара: данную фичу не используем, поскольку этот параметр, скорее всего, присваивается инкрементально каждому новому товару. Видится, что какие-либо закономерности здесь отсутствуют.

**text_fields** - содержит словарь со следующими полями:
    ***title*** - наименование товара: скорее всего, ключевая фича. Видится, что содержимое данного поля имеет наибольшую корреляцию с категорией товаров.
    ***description*** - описание товара (раздел на странице товара - описание товара): тоже одна из ключевых фич. Однако, как было сказано выше, представление данных в ней облададает большими различиями, поэтому влияние данного поля на итоговый score видится умеренным.
    ***attributes*** - описание товара тезисно (раздел на странице товара - кратко о товаре): тоже одна из ключевых фич. Однако, подробность описания ниже чем в description, поэтому влияние данного поля на итоговый score видится умеренным.
    ***custom_characteristics*** - характеристики товара: вторичная фича. Влияние данной фичи на итоговый score видится слабым, поскольку значения характеристик могут быть одинаковыми среди большого количества категорий.
    ***defined_characteristics*** - характеристики товара: вторичная фича. Влияние данной фичи на итоговый score видится слабым, поскольку значения характеристик могут быть одинаковыми среди большого количества категорий.
    ***filters*** - параметры фильтров в категории: вторичная фича. Влияние данной фичи на итоговый score видится крайне слабым, поскольку значения фильтров могут быть одинаковыми среди значительного количества категорий.

**rating** - средний рейтинг товара: данную фичу не используем. Рейтинг товара никак не может определять категорию, в которой находится товар, не говоря о том, что по условию задания на этапе заведения магазином карточки товара его рейтинг вообще не может быть определен.

**sale** - флаг, обозначающий, находится ли товар в распродаже: данную фичу не используем. Нахождение товара в распродаже никак не может определять категорию, в которой находится товар, не говоря о том, что магазин, исходя из собственной стратегии продвижения/продажи товара, может когда угодно и сколь угодно часто менять данный флаг.

**shop_id, shop_title** - соответственно, уникальный идентификатор магазина и уникальное наименование магазина: скорее всего, ключевая фича. Данные выводы следуют из размышления о том, что каждый из магазинов специализируется в своей деятельности в каком-то определенном направлении. Так магазин, занимающийся продажей одежды, будет иметь товары соответствующих одежде категорий. Но, соответственно, не будет представлен в пищевых продуктах, электронике и т. п. Поскольку в дальнейшей обработке будем работать с текстом, то для простоты мы в дальнейшем будем использовать только shop_title вместо shop_id.
    
**category_id, category_name** - соответственно, уникальный идентификатор категории товара и уникальное наименование категории: целевая переменная, используем по условиям задания только category_id вместо category_name.


## 2. Feature engeneering

Для создания фич из текста использовался CountVectorizer() из библиотеки scikit-learn. Для корректировки весов слов получившегося словаря использовался TfidfTransformer() из библиотеки scikit-learn.

CountVectorizer() не является уникальным в своем роде решением. Однако текст описаний товаров далек от сложных синтаксических конструкций и больше представляет собой набор тезисов. В таком случае использование CountVectorizer() видится оправданным. 

## 3. Modeling

Для модели использовалась стратегия one-vs-rest и классификатор OneVsRestClassifier() из библиотеки scikit-learn. В качестве estimator использовался LinearSVC() из библиотеки scikit-learn.

## 4. Evaluation

На не подверженных чистке данных кросс-валидация дала score не ниже 0.85. Далее начались поиски по улучшению результата.

#### Чистка мусора

Еще на EDA было обнаружено, что данные в своем представлении сильно разнятся. И хотя CountVectorizer() справился достаточно неплохо, тем не менее при анализе словаря было обнаружено большое количество "мусора". Экспериментально были удалены iframe и img теги, что сразу же дало рост score. В конечном итоге было принято решение удалить все html теги, для чего была написана соответствующая процедура. С учетом данной чистки, score стал не ниже 0.857

Дальнейший анализ словаря после такой чистки показал наличие большого количества низкочастотных слов, представляющих собой сочетание букв и цифр или только цифр. При первом приближении казалось, что чистка слов соответствующих этому критерию даст увеличение score. Однако, результат оказался прямо противоположным.

В итоге остановился только на чистке html тегов.

#### Влияние фич

Анализ влияния фич показал, что наилучший эффект на score оказывают те, что получены из полей title и shop_title, но поле title дает наибольший эффект. Поля description, attributes, custom_characteristics, defined_characteristics дают околонейтральный эффект. Поле filters дает скорее умеренно негативный эффект. Экспериментируя с корректировками весов полей, в итоге было установлено, что 4-х кратное увеличение веса поля title и 2-х кратное shop_title, а также удаление поля filters дают наибольший эффект. Score стал не ниже 0.872.

#### Параметры LinearSVC()

Экспериментирование с параметрами estimator показало отсутствие положительной реакции на score любого из параметров, кроме параметра регуляризации (C). Получилось, что наилучший результат достигается при C~1.8.

#### Максимальное значение score

Максимальное значение среднего score (в качестве метрики по условиям задания использовалась f1_weighted) достигнутое при кросс-валидации на 5 фолдах составило 0,87584. Необходимо отметить, что с увеличением количества фолдов максимальное значение среднего score достигнутое при кросс-валидации продолжало свой рост к 0,88.

## 5. Выводы

Способ предъявляет невысокие требования к вычислительным ресурсам для решения поставленной задачи. Кросс-валидация на 5 фолдах выполняется менее чем за 6 минут на машине с Ryzen 5 5600X и 16 Гб оперативной памяти.

Приведенный способ решения имеет достаточно высокую точность, количество угаданных категорий более 87% на обучающем наборе.

Анализ ошибочно предсказанных данных на тестовом наборе показывает, что различие между действительной категорией и предсказанной в большинстве случаев едва уловимо даже при ручной обработке. Зачастую единственно возможным фактором определяющим принадлежность к той или иной категории является изображение. В других случаях наблюдается двойственность когда один и тот же товар правомерно может быть отнесен и к действительной и к предсказанной категории.

Также точность модели такова, что позволяет обнаруживать ошибки допущенные площадкой при отнесении товара к той или иной категории. Так например [товар](https://kazanexpress.ru/product/Zhenskaya-futbolka-korichnevaya-s-printom-Zarka-1546301) отнесен площадкой к категории **Все категории->Одежда->Женская одежда->Футболки и топы->Поло**, а предсказана категория **Все категории->Одежда->Женская одежда->Футболки и топы->Футболки**. При ручном анализе данного товара становится очевидно, что ни по описанию ни по изображению товар к Поло не относится. Поло это футболка у которой воротник имеет сходство с таковым у рубашки. Случаи таких ошибок не еденичны.

Анализ словаря полученного с использованием CountVectorizer() показывает большое количество однокоренных слов, одних и тех же слов в разном падеже, с разными суффиксами, окончаниями и т. п. В виду этого достижение более высокого результата, видится возможным при использовании лемматизации, использовании решений учитывающих контекстуальное отношение слов, а также объединении фич, полученных из текста и из набора изображений (не использовались в решении). Также увеличение размера обучающей выборки видится одним из решений, которое позволит увеличить точность предсказания.

## 6. Итоги

По опубликованным организаторами данным на тестовой выборке решение заняло 5-ое место с результатом [0,8872](https://remarkable-cockatoo-98b.notion.site/Leaderboard-9f087f0b6b5c4213ba690ef77eaaa016) 
